import{_ as s,c as i,o as a,a7 as t}from"./chunks/framework.B28k8k1F.js";const g=JSON.parse('{"title":"LLM在洗钱规律中的发现和技术实现","description":"","frontmatter":{"sidebar":false,"cover":"https://cdn.jsdelivr.net/gh/hyperter96/tech-blog/docs/assets/images/background2.jpg","date":"2025-2-4","tag":["AI","人工智能","AML","区块链"],"sticky":1,"head":[]},"headers":[],"relativePath":"posts/ai/llm-for-aml.md","filePath":"posts/ai/llm-for-aml.md","lastUpdated":1739696112000}'),n={name:"posts/ai/llm-for-aml.md"},l=t(`<h1 id="llm在洗钱规律中的发现和技术实现" tabindex="-1">LLM在洗钱规律中的发现和技术实现 <a class="header-anchor" href="#llm在洗钱规律中的发现和技术实现" aria-label="Permalink to &quot;LLM在洗钱规律中的发现和技术实现&quot;">​</a></h1><h2 id="规律发现的三级架构体系" tabindex="-1">规律发现的三级架构体系 <a class="header-anchor" href="#规律发现的三级架构体系" aria-label="Permalink to &quot;规律发现的三级架构体系&quot;">​</a></h2><ol><li>数据表征层</li></ol><ul><li>多粒度嵌入技术：采用层次化Transformer将结构化数据转换为768+维语义空间坐标</li><li>时序关系编码：通过时间卷积网络（TCN）捕获动态演变模式</li><li>跨模态对齐：构建数字-文本-图像的联合嵌入空间</li></ul><ol start="2"><li>模式提取层</li></ol><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> PatternMiner</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.attention </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MultiHeadSparseAttention()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.clustering </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> DynamicTopologyLearning()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, embeddings):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        context_weights </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.attention(embeddings)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.clustering(context_weights)</span></span></code></pre></div>`,6),e=[l];function h(p,k,r,d,o,E){return a(),i("div",{"data-pagefind-body":!0},e)}const y=s(n,[["render",h]]);export{g as __pageData,y as default};
